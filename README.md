# Master Thesis on Dimensionality Reduction Techniques

This repository contains the code and documentation for my master's thesis focused on dimensionality reduction techniques. The project investigates various methods for reducing the dimensionality of datasets while preserving their intrinsic properties, ultimately enhancing the performance of machine learning algorithms. All methods were implemented from scratch, showcasing a deep understanding of their underlying principles.

## Project Overview

- **Objective**: To explore and compare different dimensionality reduction techniques, such as PCA, t-SNE, and UMAP, and analyze their effectiveness in various contexts, including classification and clustering tasks.
- **Datasets**: A variety of datasets are used, ranging from synthetic data to real-world applications, allowing for comprehensive evaluation and analysis.

## Key Features

- **Dimensionality Reduction Methods**:
  - **Principal Component Analysis (PCA)**: A linear method used for identifying the directions (principal components) that maximize variance in the data.
  - **t-Distributed Stochastic Neighbor Embedding (t-SNE)**: A nonlinear method particularly effective for visualizing high-dimensional data in lower dimensions.
  - **Uniform Manifold Approximation and Projection (UMAP)**: A newer method that preserves more of the global structure of the data compared to t-SNE.

- **Implementation**: All dimensionality reduction techniques were implemented from scratch, allowing for a better understanding of the algorithms and their functionalities.

- **Evaluation Metrics**:
  - Comparative analysis of the performance of each dimensionality reduction technique using metrics such as explained variance, silhouette score, and clustering quality.

- **Visualization**:
  - Good visualizations of the reduced-dimensional representations of the datasets to facilitate understanding of the data structure and the effectiveness of each technique.
